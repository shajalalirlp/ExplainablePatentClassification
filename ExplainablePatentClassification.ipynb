{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a955c27-154d-4a67-a086-64a199b3286a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 07:46:43.918766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb28b38-6b9a-40d4-ae0a-7bbf0bb737ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from numpy import newaxis as na\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f9a5bc-a711-40d5-932c-262b619dd226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape,  MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D, MaxPool1D\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# preparing input to our mode\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3084bc-3763-4927-b679-3e8088ba7fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e55d612-7f4e-42da-ab9e-6d8407b83687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1437c17-4da4-483f-ba5d-d61a8f66b360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('Data/PatentData.csv')\n",
    "#test_df = pd.read_csv('Data/ccdv/test_processed.csv')\n",
    "#val_df = pd.read_csv('Data/ccdv/val_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb74aef-443d-443f-b923-f8b95f12708f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372910, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a331a2e6-7c68-487a-813f-44cb9ebcad9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14eb2296-e69c-48e0-8406-575095c14446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8788730</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>1. A method for sending a keycode of a non-key...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8621421</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>1. A method executed at least in part in a com...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9461433</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>1. A light-emitting device comprising: a base;...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9229528</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1. An input apparatus, comprising: a plurality...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8508147</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>1. A dimmer circuit, comprising: a bleeder as ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id        date  \\\n",
       "0           0  8788730  2014-07-22   \n",
       "1           1  8621421  2013-12-31   \n",
       "2           2  9461433  2016-10-04   \n",
       "3           3  9229528  2016-01-05   \n",
       "4           4  8508147  2013-08-13   \n",
       "\n",
       "                                                text  class  \n",
       "0  1. A method for sending a keycode of a non-key...      8  \n",
       "1  1. A method executed at least in part in a com...      7  \n",
       "2  1. A light-emitting device comprising: a base;...      8  \n",
       "3  1. An input apparatus, comprising: a plurality...      7  \n",
       "4  1. A dimmer circuit, comprising: a bleeder as ...      8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7152eaf2-8f9f-4585-87ec-cf1747d161fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[['text','class']]\n",
    "#test_df = test_df[['abstract','class']]\n",
    "#val_df = test_df[['abstract','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdefee5-f278-4a78-91fd-9a02cccecb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. A method for sending a keycode of a non-key...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. A method executed at least in part in a com...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. A light-emitting device comprising: a base;...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. An input apparatus, comprising: a plurality...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. A dimmer circuit, comprising: a bleeder as ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  1. A method for sending a keycode of a non-key...      8\n",
       "1  1. A method executed at least in part in a com...      7\n",
       "2  1. A light-emitting device comprising: a base;...      8\n",
       "3  1. An input apparatus, comprising: a plurality...      7\n",
       "4  1. A dimmer circuit, comprising: a bleeder as ...      8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074ec17e-a68c-4b5a-803f-8facd616a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862ad31d-4675-4386-b7e6-2cd9805c9e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_x = train_df['abstract']\\ntest_x = test_df['abstract']\\nvalid_x = val_df['abstract']\\nencoder = sklearn.preprocessing.LabelEncoder()\\ntrain_y = encoder.fit_transform(train_df['class'])\\ntest_y = encoder.fit_transform(test_df['class'])\\nvalid_y = encoder.fit_transform(val_df['class'])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_x = train_df['abstract']\n",
    "test_x = test_df['abstract']\n",
    "valid_x = val_df['abstract']\n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_df['class'])\n",
    "test_y = encoder.fit_transform(test_df['class'])\n",
    "valid_y = encoder.fit_transform(val_df['class'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36879ea6-5376-4dca-b7b0-87d6c7bc1bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(train_df['text'], train_df['class'], test_size=0.20)\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_x, train_y, test_size=0.15)\n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "test_y = encoder.fit_transform(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea444085-2ad6-4f08-b6e1-884df8b88dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_features = 32000\n",
    "\n",
    "maxlen = 300\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbaad46-6780-4ffd-9ce7-a8289b828e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer  = Tokenizer(num_words = max_features)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "train_seq =  tokenizer.texts_to_sequences(train_x)\n",
    "val_seq =  tokenizer.texts_to_sequences(valid_x)\n",
    "test_seq = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_x = pad_sequences(train_seq, maxlen=maxlen, dtype='int32', padding='post') #maxlen = maxlen, padding='post')\n",
    "valid_x = pad_sequences(val_seq, maxlen=maxlen, dtype='int32', padding='post') #maxlen = maxlen, padding='post')\n",
    "test_x = pad_sequences(test_seq, maxlen=maxlen, dtype='int32', padding='post') #maxlen = maxlen, padding='post')\n",
    "\n",
    "train_y = np.asarray(train_y)\n",
    "valid_y = np.asarray(valid_y)\n",
    "test_y = np.asarray(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cac7248d-0e34-4da8-8604-e8776d603a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words : 53809\n",
      "Shape of training data tensor: (68000, 300)\n",
      "Shape of training label tensor: (68000,)\n",
      "Shape of val data tensor: (12000, 300)\n",
      "Shape of val label tensor: (12000,)\n",
      "Shape of test data tensor: (20000, 300)\n",
      "Shape of test label tensor: (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words : {}\".format(len(word_index)))\n",
    "\n",
    "\n",
    "print('Shape of training data tensor:', train_x.shape)\n",
    "print('Shape of training label tensor:', train_y.shape)\n",
    "\n",
    "print('Shape of val data tensor:', valid_x.shape)\n",
    "print('Shape of val label tensor:', valid_y.shape)\n",
    "\n",
    "print('Shape of test data tensor:', test_x.shape)\n",
    "print('Shape of test label tensor:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa87b331-6e03-459e-a64d-48a612f55f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#from gensim.models import Word2Vec\n",
    "\n",
    "#word_vectors = Word2Vec.load('Data/embedding/wiki-news-300d-1M.vec')\n",
    "word_vectors = KeyedVectors.load_word2vec_format('Data/embedding/wiki-news-300d-1M.vec')\n",
    "#word_vectors = Word2Vec.load('./models/posts.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac828bd1-1af9-4773-88f3-a0923974a765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORDS=93870\n",
    "EMBEDDING_DIM=300\n",
    "\n",
    "vocabulary_size=len(tokenizer.word_index)+1\n",
    "word_index=tokenizer.word_index\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector=word_vectors[word]\n",
    "        embedding_matrix[i]=embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d06532d5-3ac4-4c1d-90a0-03495d778eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_layer=Embedding(vocabulary_size, EMBEDDING_DIM, weights=[embedding_matrix],trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f1135-48b8-4bff-9eed-03e5e2a5e93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a46b7642-a481-4dbe-b259-50dd837715ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BiLSTM_Model():\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SpatialDropout1D(0.5))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units=9, activation='softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b60ca79-c25c-4f6a-b6d8-a20373ef34d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 07:49:31.129110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30925 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:25:00.0, compute capability: 7.0\n",
      "2023-06-05 07:49:32.201483: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:32.202908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:32.204083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:32.318320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:32.358657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:32.359743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:32.360779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:32.541359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:32.542942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:32.543967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:32.658393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:32.698591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:32.699823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:32.700841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         16143000  \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, None, 300)        0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,380,577\n",
      "Trainable params: 237,577\n",
      "Non-trainable params: 16,143,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53ee13de-c5e9-45e2-a680-6a05fa07e778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 07:49:33.118132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:33.119816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:33.120902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:33.239918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:33.282610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:33.283825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:33.284913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:33.449140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:33.450829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:33.451915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:33.570797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:33.613337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:33.614518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:33.615592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:33.902475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:34.145182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:35.130149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:35.131935: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:35.133196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:35.250621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:35.292119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:35.293334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:35.294448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:35.455199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:35.456795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:35.457859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:35.573167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:35.614925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:49:35.616123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:49:35.617195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:49:35.898808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:36.140271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:49:37.665535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-05 07:49:37.948887: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f33baec8b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-05 07:49:37.948935: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-06-05 07:49:37.953439: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-05 07:49:38.120270: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125/2125 [==============================] - ETA: 0s - loss: 1.2990 - accuracy: 0.4950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 07:51:57.355355: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:51:57.356642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:51:57.358070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:51:57.477289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:51:57.519194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:51:57.520334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:51:57.521393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:51:57.683727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:51:57.685387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:51:57.686474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 07:51:57.805975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 07:51:57.848140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 07:51:57.849277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 07:51:57.850305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125/2125 [==============================] - 156s 71ms/step - loss: 1.2990 - accuracy: 0.4950 - val_loss: 1.1017 - val_accuracy: 0.5807\n",
      "Epoch 2/30\n",
      "2125/2125 [==============================] - 160s 75ms/step - loss: 1.1412 - accuracy: 0.5654 - val_loss: 1.0258 - val_accuracy: 0.6159\n",
      "Epoch 3/30\n",
      "2125/2125 [==============================] - 151s 71ms/step - loss: 1.0802 - accuracy: 0.5925 - val_loss: 0.9860 - val_accuracy: 0.6292\n",
      "Epoch 4/30\n",
      "2125/2125 [==============================] - 158s 74ms/step - loss: 1.0437 - accuracy: 0.6068 - val_loss: 0.9609 - val_accuracy: 0.6393\n",
      "Epoch 5/30\n",
      "2125/2125 [==============================] - 153s 72ms/step - loss: 1.0113 - accuracy: 0.6177 - val_loss: 0.9542 - val_accuracy: 0.6416\n",
      "Epoch 6/30\n",
      "2125/2125 [==============================] - 150s 70ms/step - loss: 0.9871 - accuracy: 0.6280 - val_loss: 0.9297 - val_accuracy: 0.6476\n",
      "Epoch 7/30\n",
      "2125/2125 [==============================] - 146s 69ms/step - loss: 0.9658 - accuracy: 0.6343 - val_loss: 0.9105 - val_accuracy: 0.6553\n",
      "Epoch 8/30\n",
      "2125/2125 [==============================] - 149s 70ms/step - loss: 0.9494 - accuracy: 0.6424 - val_loss: 0.9055 - val_accuracy: 0.6603\n",
      "Epoch 9/30\n",
      "2125/2125 [==============================] - 152s 72ms/step - loss: 0.9315 - accuracy: 0.6509 - val_loss: 0.8976 - val_accuracy: 0.6618\n",
      "Epoch 10/30\n",
      "2125/2125 [==============================] - 153s 72ms/step - loss: 0.9184 - accuracy: 0.6532 - val_loss: 0.8842 - val_accuracy: 0.6660\n",
      "Epoch 11/30\n",
      "2125/2125 [==============================] - 153s 72ms/step - loss: 0.9065 - accuracy: 0.6557 - val_loss: 0.8819 - val_accuracy: 0.6680\n",
      "Epoch 12/30\n",
      "2125/2125 [==============================] - 149s 70ms/step - loss: 0.8965 - accuracy: 0.6609 - val_loss: 0.8945 - val_accuracy: 0.6637\n",
      "Epoch 13/30\n",
      "2125/2125 [==============================] - 147s 69ms/step - loss: 0.8832 - accuracy: 0.6656 - val_loss: 0.8794 - val_accuracy: 0.6697\n",
      "Epoch 14/30\n",
      "2125/2125 [==============================] - 149s 70ms/step - loss: 0.8730 - accuracy: 0.6667 - val_loss: 0.8847 - val_accuracy: 0.6697\n",
      "Epoch 15/30\n",
      "2125/2125 [==============================] - 149s 70ms/step - loss: 0.8654 - accuracy: 0.6714 - val_loss: 0.8727 - val_accuracy: 0.6727\n",
      "Epoch 16/30\n",
      "2125/2125 [==============================] - 152s 72ms/step - loss: 0.8585 - accuracy: 0.6734 - val_loss: 0.8670 - val_accuracy: 0.6727\n",
      "Epoch 17/30\n",
      "2125/2125 [==============================] - 151s 71ms/step - loss: 0.8484 - accuracy: 0.6792 - val_loss: 0.8683 - val_accuracy: 0.6763\n",
      "Epoch 18/30\n",
      "2125/2125 [==============================] - 151s 71ms/step - loss: 0.8446 - accuracy: 0.6800 - val_loss: 0.8615 - val_accuracy: 0.6752\n",
      "Epoch 19/30\n",
      "2125/2125 [==============================] - 147s 69ms/step - loss: 0.8364 - accuracy: 0.6809 - val_loss: 0.8654 - val_accuracy: 0.6781\n",
      "Epoch 20/30\n",
      "2125/2125 [==============================] - 148s 70ms/step - loss: 0.8280 - accuracy: 0.6856 - val_loss: 0.8658 - val_accuracy: 0.6705\n",
      "Epoch 21/30\n",
      "2125/2125 [==============================] - 150s 71ms/step - loss: 0.8200 - accuracy: 0.6873 - val_loss: 0.8739 - val_accuracy: 0.6727\n",
      "Epoch 22/30\n",
      "2125/2125 [==============================] - 152s 71ms/step - loss: 0.8182 - accuracy: 0.6892 - val_loss: 0.8593 - val_accuracy: 0.6810\n",
      "Epoch 23/30\n",
      "2125/2125 [==============================] - 153s 72ms/step - loss: 0.8117 - accuracy: 0.6910 - val_loss: 0.8675 - val_accuracy: 0.6779\n",
      "Epoch 24/30\n",
      "2125/2125 [==============================] - 151s 71ms/step - loss: 0.8070 - accuracy: 0.6923 - val_loss: 0.8660 - val_accuracy: 0.6781\n",
      "Epoch 25/30\n",
      "2125/2125 [==============================] - 146s 68ms/step - loss: 0.8013 - accuracy: 0.6940 - val_loss: 0.8729 - val_accuracy: 0.6774\n",
      "Epoch 26/30\n",
      "2125/2125 [==============================] - 153s 72ms/step - loss: 0.7984 - accuracy: 0.6962 - val_loss: 0.8716 - val_accuracy: 0.6774\n",
      "Epoch 27/30\n",
      "2125/2125 [==============================] - 151s 71ms/step - loss: 0.7930 - accuracy: 0.6987 - val_loss: 0.8745 - val_accuracy: 0.6760\n",
      "Epoch 28/30\n",
      "2125/2125 [==============================] - 161s 76ms/step - loss: 0.7857 - accuracy: 0.6994 - val_loss: 0.8729 - val_accuracy: 0.6743\n",
      "Epoch 29/30\n",
      "2125/2125 [==============================] - 152s 72ms/step - loss: 0.7867 - accuracy: 0.6986 - val_loss: 0.8962 - val_accuracy: 0.6747\n",
      "Epoch 30/30\n",
      "2125/2125 [==============================] - 152s 72ms/step - loss: 0.7833 - accuracy: 0.7012 - val_loss: 0.8724 - val_accuracy: 0.6787\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=32, epochs=30, verbose=1, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "835da00c-00e2-4ca9-9191-1b88453509fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label=\"Accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"Validation accuracy\")\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf1e6219-5274-462e-b427-24c8850c0dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 09:05:19.222191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 09:05:19.223363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 09:05:19.224675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 09:05:19.336285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 09:05:19.375994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 09:05:19.377098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 09:05:19.378073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 09:05:19.539779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 09:05:19.540889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 09:05:19.542120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-05 09:05:19.653531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-05 09:05:19.692439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-05 09:05:19.693520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-05 09:05:19.694502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 20s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a88883ff-baa1-4a6d-9cfd-a342187c4ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc263893-e226-4a76-93d2-772d5dd87527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "print(classification_report(test_y, y_pred,  target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664d681-bc8a-46c8-9c0f-7adac6484b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abe61f-43e5-40ad-b9d7-64e228bf1a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8c3a07a-a492-4202-a4c6-7a672a978cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CNN_Model():\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Convolution1D(100, 3, activation=\"relu\"))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    #model.add(Bidirectional(LSTM(32)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(9, activation=\"softmax\"))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33f19f82-da8c-447c-a338-2e30302e8651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         9434700   \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, None, 300)        0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 100)         90100     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 100)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9525709 (36.34 MB)\n",
      "Trainable params: 91009 (355.50 KB)\n",
      "Non-trainable params: 9434700 (35.99 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "CNN_model = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64993ad9-0108-401d-b092-da7b2aa517bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "532/532 [==============================] - 5s 7ms/step - loss: 1.6736 - accuracy: 0.4072 - val_loss: 1.4837 - val_accuracy: 0.4953\n",
      "Epoch 2/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.4439 - accuracy: 0.5009 - val_loss: 1.4155 - val_accuracy: 0.5103\n",
      "Epoch 3/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.3913 - accuracy: 0.5170 - val_loss: 1.3914 - val_accuracy: 0.5160\n",
      "Epoch 4/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.3635 - accuracy: 0.5301 - val_loss: 1.3610 - val_accuracy: 0.5193\n",
      "Epoch 5/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.3504 - accuracy: 0.5314 - val_loss: 1.3682 - val_accuracy: 0.5093\n",
      "Epoch 6/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.3372 - accuracy: 0.5322 - val_loss: 1.3430 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.3237 - accuracy: 0.5421 - val_loss: 1.3283 - val_accuracy: 0.5347\n",
      "Epoch 8/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.3120 - accuracy: 0.5431 - val_loss: 1.3305 - val_accuracy: 0.5357\n",
      "Epoch 9/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.3097 - accuracy: 0.5442 - val_loss: 1.3088 - val_accuracy: 0.5390\n",
      "Epoch 10/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.2982 - accuracy: 0.5472 - val_loss: 1.3107 - val_accuracy: 0.5417\n",
      "Epoch 11/50\n",
      "532/532 [==============================] - 4s 7ms/step - loss: 1.2934 - accuracy: 0.5521 - val_loss: 1.3105 - val_accuracy: 0.5457\n",
      "Epoch 12/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.2864 - accuracy: 0.5529 - val_loss: 1.3049 - val_accuracy: 0.5360\n",
      "Epoch 13/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2798 - accuracy: 0.5526 - val_loss: 1.2933 - val_accuracy: 0.5443\n",
      "Epoch 14/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.2700 - accuracy: 0.5565 - val_loss: 1.2834 - val_accuracy: 0.5517\n",
      "Epoch 15/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2693 - accuracy: 0.5579 - val_loss: 1.2802 - val_accuracy: 0.5557\n",
      "Epoch 16/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2662 - accuracy: 0.5588 - val_loss: 1.2854 - val_accuracy: 0.5540\n",
      "Epoch 17/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2553 - accuracy: 0.5652 - val_loss: 1.2798 - val_accuracy: 0.5490\n",
      "Epoch 18/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2600 - accuracy: 0.5639 - val_loss: 1.2727 - val_accuracy: 0.5563\n",
      "Epoch 19/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2518 - accuracy: 0.5652 - val_loss: 1.2708 - val_accuracy: 0.5563\n",
      "Epoch 20/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2455 - accuracy: 0.5714 - val_loss: 1.2809 - val_accuracy: 0.5507\n",
      "Epoch 21/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2362 - accuracy: 0.5674 - val_loss: 1.2678 - val_accuracy: 0.5613\n",
      "Epoch 22/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2354 - accuracy: 0.5727 - val_loss: 1.2584 - val_accuracy: 0.5647\n",
      "Epoch 23/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.2324 - accuracy: 0.5696 - val_loss: 1.2608 - val_accuracy: 0.5573\n",
      "Epoch 24/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2291 - accuracy: 0.5751 - val_loss: 1.2527 - val_accuracy: 0.5607\n",
      "Epoch 25/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2259 - accuracy: 0.5769 - val_loss: 1.2569 - val_accuracy: 0.5643\n",
      "Epoch 26/50\n",
      "532/532 [==============================] - 3s 7ms/step - loss: 1.2234 - accuracy: 0.5745 - val_loss: 1.2529 - val_accuracy: 0.5640\n",
      "Epoch 27/50\n",
      "532/532 [==============================] - 4s 7ms/step - loss: 1.2158 - accuracy: 0.5798 - val_loss: 1.2475 - val_accuracy: 0.5677\n",
      "Epoch 28/50\n",
      "532/532 [==============================] - 4s 7ms/step - loss: 1.2100 - accuracy: 0.5819 - val_loss: 1.2444 - val_accuracy: 0.5693\n",
      "Epoch 29/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2036 - accuracy: 0.5842 - val_loss: 1.2411 - val_accuracy: 0.5697\n",
      "Epoch 30/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2039 - accuracy: 0.5798 - val_loss: 1.2409 - val_accuracy: 0.5657\n",
      "Epoch 31/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.2002 - accuracy: 0.5827 - val_loss: 1.2392 - val_accuracy: 0.5690\n",
      "Epoch 32/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1969 - accuracy: 0.5861 - val_loss: 1.2384 - val_accuracy: 0.5730\n",
      "Epoch 33/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1946 - accuracy: 0.5858 - val_loss: 1.2308 - val_accuracy: 0.5693\n",
      "Epoch 34/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1842 - accuracy: 0.5917 - val_loss: 1.2325 - val_accuracy: 0.5730\n",
      "Epoch 35/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1820 - accuracy: 0.5869 - val_loss: 1.2347 - val_accuracy: 0.5747\n",
      "Epoch 36/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1782 - accuracy: 0.5930 - val_loss: 1.2302 - val_accuracy: 0.5780\n",
      "Epoch 37/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1759 - accuracy: 0.5941 - val_loss: 1.2387 - val_accuracy: 0.5690\n",
      "Epoch 38/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1740 - accuracy: 0.5871 - val_loss: 1.2272 - val_accuracy: 0.5743\n",
      "Epoch 39/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1699 - accuracy: 0.5912 - val_loss: 1.2276 - val_accuracy: 0.5803\n",
      "Epoch 40/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1666 - accuracy: 0.5968 - val_loss: 1.2240 - val_accuracy: 0.5773\n",
      "Epoch 41/50\n",
      "532/532 [==============================] - 3s 6ms/step - loss: 1.1669 - accuracy: 0.5974 - val_loss: 1.2237 - val_accuracy: 0.5807\n",
      "Epoch 42/50\n",
      "454/532 [========================>.....] - ETA: 0s - loss: 1.1608 - accuracy: 0.5960"
     ]
    }
   ],
   "source": [
    "CNN_history = CNN_model.fit(train_x, train_y, batch_size=32, epochs=50, verbose=1, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fef61bf-df09-4f6a-af5f-3d397206fa32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = CNN_model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5dba62-c134-4475-8bfe-0392e5bdc074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "print(classification_report(test_y, y_pred,  target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2376d8b-abf2-415d-b885-397190a692b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73185b8d-c52c-489a-82e0-b65eb27a5290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rnn_gru():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SpatialDropout1D(0.5))\n",
    "    model.add(GRU(100))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(9, activation=\"softmax\"))\n",
    "    model.compile(loss = '`', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d8f6e-74a3-4063-b724-5462b711761f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_gru = rnn_gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00c473-68d1-4c3b-8e4f-56758296dccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_gru = rnn_gru.fit(train_x, train_y, batch_size=32, epochs=50, verbose=1, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9871ccf1-9dd7-4c12-8800-bdc576ddf0df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = rnn_gru.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da395422-80b4-4d0d-a53a-e55b8de6c1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "print(classification_report(test_y, y_pred,  target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fe89f-f823-47b2-a2fe-a181e35b3a1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df4a31-1f78-4028-96cb-b59fc02519c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CNN_LSTM_Model():\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Convolution1D(100, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    #model.add(LSTM(32))\n",
    "    #model.add(Dense(units=1, activation='sigmoid'))\n",
    "    #model.add(GlobalAveragePooling1D())\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(LSTM(32))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(9, activation=\"softmax\"))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793c0ea-6c89-4092-90ea-954aed8f3dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CNN_LSTM_Model = CNN_LSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4856ed-d997-44c3-9ece-eed177f63cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CNN_LSTM_history = CNN_LSTM_Model.fit(train_x, train_y, batch_size=32, epochs=20, verbose=1, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "584d82e4-8f55-470f-b75c-b36741150479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = CNN_LSTM_Model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0875f7a-45e5-4823-befe-97293ccf0adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "print(classification_report(test_y, y_pred,  target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9994a2-14ba-499b-a765-ad13a1946877",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd22d4-6fba-4222-8da9-c660b4f1e322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rnn_lstm():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(9, activation=\"softmax\"))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764d43e-3364-4539-bf70-6ef029fb145d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_lstm = rnn_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf36f21-d410-4b7d-9b16-09d6e02b98d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_lstm = rnn_lstm.fit(train_x, train_y, batch_size=64, epochs=50, verbose=1, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e44fe403-8137-498d-b5f9-128ad8822c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = rnn_lstm.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032d025-92a1-455b-82c8-fdaad1d54a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "print(classification_report(test_y, y_pred,  target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f4c1c-7726-43e9-b4da-62a54d64f785",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explaining Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579c53bd-059a-49de-93ed-e90c593e7808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_layer_output(layer_name, data):\n",
    "    # https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "    intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer(layer_name).output)\n",
    "    return intermediate_layer_model.predict(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b61c2-9df7-45ea-b86e-d8bc749c1ab2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Different layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caa1adb2-df83-4f8e-8707-d6c21db85b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding/embeddings:0\n",
      "bidirectional/forward_lstm/lstm_cell_1/kernel:0\n",
      "bidirectional/forward_lstm/lstm_cell_1/recurrent_kernel:0\n",
      "bidirectional/forward_lstm/lstm_cell_1/bias:0\n",
      "bidirectional/backward_lstm/lstm_cell_2/kernel:0\n",
      "bidirectional/backward_lstm/lstm_cell_2/recurrent_kernel:0\n",
      "bidirectional/backward_lstm/lstm_cell_2/bias:0\n",
      "bidirectional_1/forward_lstm_1/lstm_cell_4/kernel:0\n",
      "bidirectional_1/forward_lstm_1/lstm_cell_4/recurrent_kernel:0\n",
      "bidirectional_1/forward_lstm_1/lstm_cell_4/bias:0\n",
      "bidirectional_1/backward_lstm_1/lstm_cell_5/kernel:0\n",
      "bidirectional_1/backward_lstm_1/lstm_cell_5/recurrent_kernel:0\n",
      "bidirectional_1/backward_lstm_1/lstm_cell_5/bias:0\n",
      "dense/kernel:0\n",
      "dense/bias:0\n",
      "dense_1/kernel:0\n",
      "dense_1/bias:0\n"
     ]
    }
   ],
   "source": [
    "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
    "weights = model.get_weights()\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    print(name)\n",
    "    #print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de1298-4bb4-42ff-b9d1-2e0213982310",
   "metadata": {
    "tags": []
   },
   "source": [
    "# catching weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba03d821-c13e-4939-9527-2dc5d5a8b7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    if name == 'bidirectional/backward_lstm/lstm_cell_2/kernel:0':\n",
    "        kernel_0 = weight\n",
    "    if name == 'bidirectional/backward_lstm/lstm_cell_2/recurrent_kernel:0':\n",
    "        recurrent_kernel_0 = weight\n",
    "    if name == 'bidirectional/backward_lstm/lstm_cell_2/bias:0':\n",
    "        bias_0 = weight\n",
    "    elif name == 'dense/kernel:0':\n",
    "        output = weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "290b7718-85eb-44c2-acc8-8538de85b26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_0 (300, 256)\n",
      "recurrent_kernel_0 (64, 256)\n",
      "bias_0 (256,)\n",
      "output (64, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"kernel_0\", kernel_0.shape)\n",
    "print(\"recurrent_kernel_0\", recurrent_kernel_0.shape)\n",
    "print(\"bias_0\", bias_0.shape)\n",
    "print(\"output\", output.shape)\n",
    "\n",
    "# self.Wxh_Left (240, 60)\n",
    "# self.Whh_Left (240, 60)\n",
    "# self.bxh_Left (240,)\n",
    "# self.Why_Left (5, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66bc56cc-f2f7-4537-a197-b6180821c195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxh (256, 300)\n",
      "Whh (256, 64)\n",
      "bxh (256,)\n",
      "Why (128, 64)\n"
     ]
    }
   ],
   "source": [
    "Wxh = kernel_0.T  # shape 4d*e\n",
    "Whh = recurrent_kernel_0.T  # shape 4d\n",
    "bxh = bias_0.T  # shape 4d \n",
    "Why = output.T\n",
    "\n",
    "print(\"Wxh\", Wxh.shape)\n",
    "print(\"Whh\", Whh.shape)\n",
    "print(\"bxh\", bxh.shape)\n",
    "print(\"Why\", Why.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3f223-2c24-4638-878c-a49a04392a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bda0e2af-ae47-47a5-bda2-faad4fc12187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_set = set(stopwords.words(\"english\"))\n",
    "if 'on' in stopword_set:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1887c-6a6e-470c-b9cb-e94c22fe4c59",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dictionary to word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a079977a-5b1c-4b77-b149-fce8da64362b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    word_cloud = WordCloud(\\n        width=7000,\\n        height=3000,\\n        random_state=1,\\n        background_color=\"salmon\",\\n        colormap=\"Pastel1\",\\n        collocations=False,\\n        stopwords=STOPWORDS,\\n        ).generate_from_frequencies(dictionay)\\n    plt.imshow(word_cloud)\\n    plt.axis(\"off\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "def dictionary_word_to_score(words, scores):\n",
    "    #assert len(words)==len(scores)\n",
    "    max_s     = max(scores)\n",
    "    min_s     = min(scores)\n",
    "    \n",
    "    dictionay = {}\n",
    "    #print(len(words))\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in stopword_set:\n",
    "            score = 0.5\n",
    "        else:\n",
    "            if idx < len(scores):\n",
    "                score = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
    "        #output_text = output_text + span_word(w, score, colormap) + \" \"\n",
    "        if score > .50 :\n",
    "            if w in dictionay:\n",
    "                #print(w, \"  \", score)\n",
    "                if score > dictionay[w] :\n",
    "                    dictionay[w] = score*100\n",
    "            else:\n",
    "                dictionay[w] = score*100\n",
    "    print(dictionay)\n",
    "'''\n",
    "    word_cloud = WordCloud(\n",
    "        width=7000,\n",
    "        height=3000,\n",
    "        random_state=1,\n",
    "        background_color=\"salmon\",\n",
    "        colormap=\"Pastel1\",\n",
    "        collocations=False,\n",
    "        stopwords=STOPWORDS,\n",
    "        ).generate_from_frequencies(dictionay)\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "'''  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040d570-e076-4e46-9189-94c85ae6196c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# html heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a965b7c-eba3-4b3e-b9bb-a216fb798653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def html_heatmap (words, scores, cmap_name=\"bwr\"):\n",
    "    \"\"\"\n",
    "    Return word-level heatmap in HTML format,\n",
    "    with words being the list of words (as string),\n",
    "    scores the corresponding list of word-level relevance values,\n",
    "    and cmap_name the name of the matplotlib diverging colormap.\n",
    "    \"\"\"\n",
    "    \n",
    "    colormap  = plt.get_cmap(cmap_name)\n",
    "     \n",
    "    #assert len(words)==len(scores)\n",
    "    max_s     = max(scores)\n",
    "    min_s     = min(scores)\n",
    "    \n",
    "    output_text = \"\"\n",
    "    \n",
    "    for idx, w in enumerate(words):\n",
    "        if w in stopword_set:\n",
    "            score = 0.5\n",
    "        else:\n",
    "            score = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
    "        output_text = output_text + span_word(w, score, colormap) + \" \"\n",
    "    \n",
    "    return output_text + \"\\n\"\n",
    "\n",
    "def rescale_score_by_abs (score, max_score, min_score):\n",
    "    \"\"\"\n",
    "    Normalize the relevance value (=score), accordingly to the extremal\n",
    "    relevance values (max_score and min_score), for visualization with a \n",
    "    diverging colormap. i.e. rescale positive relevance to the range \n",
    "    [0.5, 1.0], and negative relevance to the range [0.0, 0.5],\n",
    "    using the highest absolute relevance for linear interpolation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # CASE 1: positive AND negative scores occur --------------------\n",
    "    if max_score>0 and min_score<0:\n",
    "    \n",
    "        if max_score >= abs(min_score):   # deepest color is positive\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/max_score)\n",
    "            else:\n",
    "                return 0.5 - 0.5*(abs(score)/max_score)\n",
    "\n",
    "        else:                             # deepest color is negative\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/abs(min_score))\n",
    "            else:\n",
    "                return 0.5 - 0.5*(score/min_score)   \n",
    "    \n",
    "    # CASE 2: ONLY positive scores occur -----------------------------       \n",
    "    elif max_score>0 and min_score>=0: \n",
    "        if max_score == min_score:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.5 + 0.5*(score/max_score)\n",
    "    \n",
    "    # CASE 3: ONLY negative scores occur -----------------------------\n",
    "    elif max_score<=0 and min_score<0: \n",
    "        if max_score == min_score:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 0.5 - 0.5*(score/min_score)\n",
    "          \n",
    "\n",
    "def getRGB (c_tuple):\n",
    "    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n",
    "\n",
    "     \n",
    "def span_word (word, score, colormap):\n",
    "    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09439357-bd58-4041-8238-29abfd37f278",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c74b7f1-3b75-468a-b0a1-0bc6bff07546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor=0.0, debug=False):\n",
    "    \"\"\"\n",
    "    LRP for a linear layer with input dim D and output dim M.\n",
    "    Args:\n",
    "    - hin:            forward pass input, of shape (D,)\n",
    "    - w:              connection weights, of shape (D, M)\n",
    "    - b:              biases, of shape (M,)\n",
    "    - hout:           forward pass output, of shape (M,) (unequal to np.dot(w.T,hin)+b if more than one incoming layer!)\n",
    "    - Rout:           relevance at layer output, of shape (M,)\n",
    "    - bias_nb_units:  total number of connected lower-layer units (onto which the bias/stabilizer contribution is redistributed for sanity check)\n",
    "    - eps:            stabilizer (small positive number)\n",
    "    - bias_factor:    set to 1.0 to check global relevance conservation, otherwise use 0.0 to ignore bias/stabilizer redistribution (recommended)\n",
    "    Returns:\n",
    "    - Rin:            relevance at layer input, of shape (D,)\n",
    "    \"\"\"\n",
    "    sign_out = np.where(hout[na,:]>=0, 1., -1.) # shape (1, M)\n",
    "    \n",
    "    numer    = (w * hin[:,na]) + ( bias_factor * (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units ) # shape (D, M)\n",
    "    # Note: here we multiply the bias_factor with both the bias b and the stabilizer eps since in fact\n",
    "    # using the term (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units in the numerator is only useful for sanity check\n",
    "    # (in the initial paper version we were using (bias_factor*b[na,:]*1. + eps*sign_out*1.) / bias_nb_units instead)\n",
    "    \n",
    "    denom    = hout[na,:] + (eps*sign_out*1.)   # shape (1, M)\n",
    "    \n",
    "    message  = (numer/denom) * Rout[na,:]       # shape (D, M)\n",
    "    \n",
    "    Rin      = message.sum(axis=1)              # shape (D,)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"local diff: \", Rout.sum() - Rin.sum())\n",
    "    # Note: \n",
    "    # - local  layer   relevance conservation if bias_factor==1.0 and bias_nb_units==D (i.e. when only one incoming layer)\n",
    "    # - global network relevance conservation if bias_factor==1.0 and bias_nb_units set accordingly to the total number of lower-layer connections \n",
    "    # -> can be used for sanity check\n",
    "    \n",
    "    return Rin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa731a2-2eea-4a78-ba34-159c810df07c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12d28cc9-19ef-45c7-be54-5c5cf54eae56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LRP(target_data, target_class) :\n",
    "    \n",
    "    #  E embedding    , x embedding .  \n",
    "    # w_indices [109, 11995, 25, 18263, 25, 973, 3138, 6389, 372]\n",
    "\n",
    "    x = get_layer_output('embedding', target_data)\n",
    "    e = x.shape[1]\n",
    "\n",
    "   ################# forword\n",
    "    T = target_data.shape[0]\n",
    "    d = int(256/4)  # hidden units\n",
    "    C = Why.shape[0] # number of classes\n",
    "    \n",
    "    idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n",
    "    idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n",
    "\n",
    "    h  = np.zeros((T,d))\n",
    "    c  = np.zeros((T,d))\n",
    "\n",
    "    gates_xh  = np.zeros((T, 4*d))  \n",
    "    gates_hh  = np.zeros((T, 4*d)) \n",
    "    gates_pre = np.zeros((T, 4*d))  \n",
    "    gates     = np.zeros((T, 4*d))  \n",
    "\n",
    "    for t in range(T):\n",
    "        gates_xh[t]     = np.dot(Wxh, x[t])\n",
    "        gates_hh[t]     = np.dot(Whh, h[t-1])\n",
    "        gates_pre[t]    = gates_xh[t] + gates_hh[t] + bxh\n",
    "        gates[t, idx]    = 1.0/(1.0 + np.exp(- gates_pre[t,idx]))\n",
    "        gates[t,idx_g]  = np.tanh(gates_pre[t,idx_g]) \n",
    "        c[t]            = gates[t,idx_f]*c[t-1] + gates[t,idx_i]*gates[t,idx_g]\n",
    "        h[t]            = gates[t,idx_o]*np.tanh(c[t])\n",
    "\n",
    "    s = np.dot(Why, h[t])    \n",
    "\n",
    "    ################# backwork\n",
    "    dx     = np.zeros(x.shape)\n",
    "\n",
    "    dh          = np.zeros((T, d))\n",
    "    dc          = np.zeros((T, d))\n",
    "    dgates_pre  = np.zeros((T, 4*d))  # gates pre-activation\n",
    "    dgates      = np.zeros((T, 4*d))  # gates activation\n",
    "\n",
    "    ds               = np.zeros((C))\n",
    "    ds[target_class] = 1.0\n",
    "    dy               = ds.copy()\n",
    "\n",
    "    # 0   \n",
    "    dh[T-1]     = np.dot(Why.T, dy)\n",
    "\n",
    "    for t in reversed(range(T)): \n",
    "        dgates[t,idx_o]    = dh[t] * np.tanh(c[t])  # do[t]\n",
    "        dc[t]             += dh[t] * gates[t,idx_o] * (1.-(np.tanh(c[t]))**2) # dc[t]\n",
    "        dgates[t,idx_f]    = dc[t] * c[t-1]         # df[t]\n",
    "        dc[t-1]            = dc[t] * gates[t,idx_f] # dc[t-1]\n",
    "        dgates[t,idx_i]    = dc[t] * gates[t,idx_g] # di[t]\n",
    "        dgates[t,idx_g]    = dc[t] * gates[t,idx_i] # dg[t]\n",
    "        dgates_pre[t,idx]  = dgates[t,idx] * gates[t,idx] * (1.0 - gates[t,idx]) # d ifo pre[t]\n",
    "        dgates_pre[t,idx_g]= dgates[t,idx_g] *  (1.-(gates[t,idx_g])**2) # d g pre[t]\n",
    "        dh[t-1]            = np.dot(Whh.T, dgates_pre[t])\n",
    "        dx[t]              = np.dot(Wxh.T, dgates_pre[t])\n",
    "\n",
    "    ################# LRP\n",
    "    eps=0.001 \n",
    "    bias_factor=0.0\n",
    "    Rx  = np.zeros(x.shape)\n",
    "    Rh  = np.zeros((T+1, d))\n",
    "    Rc  = np.zeros((T+1, d))\n",
    "    Rg  = np.zeros((T,   d)) # gate g only\n",
    "\n",
    "    Rout_mask            = np.zeros((C))\n",
    "    Rout_mask[target_class] = 1.0  \n",
    "\n",
    "    # format reminder: lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor)\n",
    "    Rh[T-1]  = lrp_linear(h[T-1], Why.T, np.zeros((C)), s, s*Rout_mask, 2*d, eps, bias_factor, debug=False)  \n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        Rc[t]   += Rh[t]\n",
    "        Rc[t-1]  = lrp_linear(gates[t,idx_f]*c[t-1], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n",
    "        Rg[t]    = lrp_linear(gates[t,idx_i]*gates[t,idx_g], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n",
    "        Rx[t]    = lrp_linear(x[t], Wxh[idx_g].T, bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)\n",
    "        Rh[t-1]  = lrp_linear(h[t-1], Whh[idx_g].T, bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)    \n",
    "\n",
    "    return s, dx, Rx, Rh[-1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615e898-584c-48e7-a6ce-f5013a5a6d7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# index to Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6972f8e2-1a7f-403d-b24d-b48e0203a6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#word_index = imdb.get_word_index()\n",
    "index_word = {v:k for k,v in word_index.items()}\n",
    "\n",
    "#values = ','.join(str(v) for v in value_list)\n",
    "\n",
    "def index_to_word(word):\n",
    "    full_sentence = \"\"\n",
    "    for w in word:\n",
    "        if w != 0:\n",
    "            full_sentence = full_sentence + ' ' + index_word.get(w)\n",
    "    #print('word: ', word)\n",
    "    #full_sentence = ' '.join(index_word.get(w) for w in word)\n",
    "    return full_sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028748e-a4e6-4714-becc-b5f2ccf5154d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Integer to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165fc12d-1ead-40a6-84c5-08effa84e5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def int_to_str(target_class):\n",
    "    if target_class == 1:\n",
    "        return \"Human necessities\"\n",
    "    elif target_class == 2:\n",
    "        return \"Performing_operations\"\n",
    "    elif target_class == 3:\n",
    "        return \"Chemistry\"\n",
    "    elif target_class == 4:\n",
    "        return \"Textiles\"\n",
    "    elif target_class == 5:\n",
    "        return \"Fixed_constructions\"\n",
    "    elif target_class == 6:\n",
    "        return \"Mechanical_engineering\"\n",
    "    elif target_class == 7:\n",
    "        return \"Physics\"\n",
    "    elif target_class == 8:\n",
    "        return \"Electricity\"\n",
    "    elif target_class == 9:\n",
    "        return \"General\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc06c81b-87d4-476f-9dce-c83097972957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125/2125 [==============================] - 67s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(train_x) #test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe856bc7-b99e-4abc-a0bc-637161ffd900",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Class List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79102f06-e034-4b15-a3e9-e4f193d245f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_list = []\n",
    "B_list = []\n",
    "C_list = []\n",
    "D_list = []\n",
    "E_list = []\n",
    "F_list = []\n",
    "G_list = []\n",
    "H_list = []\n",
    "Y_list = []\n",
    "\n",
    "categories = ['Human necessities', 'Performing_operations', 'Chemistry','Textiles','Fixed_constructions','Mechanical_engineering','Physics','Electricity','General']\n",
    "\n",
    "for i in range(len(train_y)): #test_y\n",
    "    if np.argmax(predictions[i]) == 1:\n",
    "        A_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 2:\n",
    "        B_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 3:\n",
    "        C_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 4:\n",
    "        D_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 5:\n",
    "        E_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 6:\n",
    "        F_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 7:\n",
    "        G_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 8:\n",
    "        H_list.append(i)\n",
    "    elif np.argmax(predictions[i]) == 9:\n",
    "        Y_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ac453f-8680-4c77-85b6-6490c12a394f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18119\n"
     ]
    }
   ],
   "source": [
    "print(len(A_list)+len(B_list)+len(C_list)+len(D_list)+len(E_list)+len(F_list)+len(G_list)+len(H_list)+len(Y_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cccb1-76d3-4d15-8030-48f752093dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sequence to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae981530-d32c-4222-9fca-32db0ed9e54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_word = {v: k for k, v in word_index.items()} # map back\n",
    "seqs = train_x #test_x\n",
    "words = []\n",
    "\n",
    "def seqToWords():\n",
    "    for seq in seqs:\n",
    "        if len(seq):\n",
    "            words.append(index_word.get(seq[0]))\n",
    "        else:\n",
    "            words.append(' ')    \n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b940a5b0-97b3-4e8c-8581-4339e4ec1e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = seqToWords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303abb7-bec8-40db-834e-2b54738b8038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sequence to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f5ccd66-73c2-494b-9b19-e391cd444806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, word_index.items()))\n",
    "\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051551a5-bc3b-4b89-ae6d-bb8bee3f5d20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Explainer Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13e97cf5-de72-4f4e-98d7-76b538d0224f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def explainer(class_list):   \n",
    "    for index, i in enumerate(class_list):\n",
    "        \n",
    "    \n",
    "        target_data = train_x[i] #test_x\n",
    "        #print(target_data)\n",
    "        #print(target_data.shape)\n",
    "        target_class = train_y[i]#test_y\n",
    "        #print(\"Target Class: \", target_class)\n",
    "        \n",
    "        #if np.argmax(predictions[i]) != target_class:\n",
    "         #   continue\n",
    "\n",
    "        scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n",
    "    \n",
    "        R_words          = np.sum(Rx, axis=1)                       # compute word-level LRP relevances\n",
    "        R_words_SA       = (np.linalg.norm(Gx,ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n",
    "        R_words_GI       = np.dot(target_data, Gx) \n",
    "    \n",
    "        words = index_to_word(target_data)\n",
    "        '''\n",
    "        try:\n",
    "            words = index_to_word(target_data)\n",
    "            #continue\n",
    "        #words = seqToWords()\n",
    "        except:\n",
    "            continue\n",
    "        '''\n",
    "        if len(words) > 0 :\n",
    "            \n",
    "            print(\"Predicted label:\", int_to_str(np.argmax(predictions[i])), \"Actual label:\", int_to_str(target_class))\n",
    "\n",
    "            print(\"LRP heatmap:\")\n",
    "            display(HTML(html_heatmap(words, R_words)))\n",
    "\n",
    "            print(\"SA heatmap:\")\n",
    "            display(HTML(html_heatmap(words, R_words_SA)))\n",
    "\n",
    "            print(\"GI heatmap:\")\n",
    "            display(HTML(html_heatmap(words, R_words_GI)))\n",
    "            \n",
    "            print(\"Word Cloud\")\n",
    "            dictionary_word_to_score(words, R_words_SA)\n",
    "\n",
    "            print(\"-----------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7abc4-d91e-4acd-8da3-d071fabc88c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explainer Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "836c27ca-715c-489f-a7f0-33157d705ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def explainer_word_cloud(class_list):   \n",
    "    for index, i in enumerate(class_list):\n",
    "    \n",
    "        target_data = test_x[i]\n",
    "        #print(target_data)\n",
    "        #print(target_data.shape)\n",
    "        target_class = np.argmax(test_y[i])\n",
    "\n",
    "        scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n",
    "    \n",
    "        R_words          = np.sum(Rx, axis=1)                       # compute word-level LRP relevances\n",
    "        R_words_SA       = (np.linalg.norm(Gx,ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n",
    "        R_words_GI       = np.dot(target_data, Gx) \n",
    "    \n",
    "        words = index_to_word(target_data)\n",
    "        '''\n",
    "        try:\n",
    "            words = index_to_word(target_data)\n",
    "            print(len(words))\n",
    "            #continue\n",
    "        #words = seqToWords()\n",
    "        except:\n",
    "            continue\n",
    "        '''\n",
    "        if len(words) > 0 :\n",
    "            print(\"Predicted label:\", int_to_str(np.argmax(predictions[i])), \"Actual label:\", int_to_str(target_class))\n",
    "\n",
    "            print(\"Word Cloud\")\n",
    "            print(\"-----------------------------------------------------------\")\n",
    "            dictionary_word_to_score(words, scores)\n",
    "\n",
    "            print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c596beb4-8ec4-4e9a-b8d8-ee3318d03922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7147\n"
     ]
    }
   ],
   "source": [
    "print(len(H_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b0b9b-07c4-404a-a331-6b0d233d6f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chemistry Example Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752eb5c-2992-463d-9441-971975312e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The degree to which each word affects the prediction of class C\")\n",
    "explainer(C_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
